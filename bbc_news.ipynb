{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13351,"databundleVersionId":324297,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":306.329052,"end_time":"2025-08-03T20:21:56.088825","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-03T20:16:49.759773","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BBC News Classification with NMF Project\n\nUniversity of Colorado, Boulder - CSCA 5632: Unsupervised Algorithms in Machine Learning\n\n## Project Overview\n\nThis project is about categorizing the BBC News articles using matrix factorization to predict the category. The project will work to follow a typical machine learning project, with an exception that the specific unsupervised model, Non-negative Matrix Factorization (NMF), is already determined. After evaluations have been perfomed for the NMF model, the project will then select and compare the performance for against a supervised model.\n\nThe code for this project can be found in my GitHubj [BBC_News](https://github.com/jfroggatt/BBC_News.git) repo.\n\nThe project notebook, [BBC News Classification with NMF](https://www.kaggle.com/code/jamesfroggatt/bbc-news-classification-with-nmf), can also be found on Kaggle, where the submission results for each of the three methods can be reviewed.\n\nThe guidelines for this project are as follows:\n\n### Step 1. Exploratory Data Analysis\n\nIn this section we will inspect, visualize, and clean the data. As part of the process, we will also select a word embedding method and review associated visualizations and statistics. Following a review of the EDA, we will then generate a plan for the analysis, including data cleaning, preprocessing, and feature engineering steps.\n\n### Step 2. Building and training the unsupervised model\n\nIn this section we will build a model using the Non-negative Matrix Factorization method and predict train and test data labels. The model's performance across various hyperparameter configurations will be evaluated to determine the optimal configuration. The performance will be inpected through results of the accuracy score and confusion matrix. Finally, we may look at additional methods to improve the final model performance.\n\n### Step 3. Compare with supervised learning\n\nIn this section we will evaluate and select a supervised model to generate the predicted category and compare the test results with the NMF model. This comparison will also include an evaluation of how each model performs based on the size of the training data.\n\n### Step 4. Project Report and Conclusion\n\nFinally, we will evaluate the project results.","metadata":{"papermill":{"duration":0.013823,"end_time":"2025-08-03T20:16:55.357757","exception":false,"start_time":"2025-08-03T20:16:55.343934","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Project Setup\n\n### Python Project Libraries\n\nImport the necessary libraries","metadata":{"papermill":{"duration":0.011291,"end_time":"2025-08-03T20:16:55.382419","exception":false,"start_time":"2025-08-03T20:16:55.371128","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from collections import Counter\nimport itertools\nimport numpy as np\nimport os\nimport pandas as pd\nimport re\n\nimport matplotlib.colors as mcolors\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport squarify as sqrf\n\nimport nltk\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom sklearn.base import BaseEstimator, TransformerMixin, clone\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, make_scorer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\n\n# Download the following required data resources if not already downloaded and needed\n\n# NLTK stopwords\nnltk.download('stopwords', quiet=True)\n\n# If using WordNetLemmatizer with POS tag support, you'll need the following NLTK data sets\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger_eng')\n\n# If using the spaCy lemmatizer, you'll need the following spaCy data set downloaded\n#  for spaCy english words:\n# !python -m spacy download en_core_web_sm\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:03:40.100065Z","start_time":"2025-08-02T17:03:38.580898Z"},"execution":{"iopub.status.busy":"2025-08-05T23:21:31.807797Z","iopub.execute_input":"2025-08-05T23:21:31.808171Z","iopub.status.idle":"2025-08-05T23:21:34.617913Z","shell.execute_reply.started":"2025-08-05T23:21:31.808135Z","shell.execute_reply":"2025-08-05T23:21:34.616770Z"},"papermill":{"duration":8.104199,"end_time":"2025-08-03T20:17:03.498747","exception":false,"start_time":"2025-08-03T20:16:55.394548","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# list project data files\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:03:43.752357Z","start_time":"2025-08-02T17:03:43.744361Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:04.633848Z","iopub.execute_input":"2025-08-04T05:13:04.634340Z","iopub.status.idle":"2025-08-04T05:13:04.640759Z","shell.execute_reply.started":"2025-08-04T05:13:04.634315Z","shell.execute_reply":"2025-08-04T05:13:04.639524Z"},"papermill":{"duration":0.02365,"end_time":"2025-08-03T20:17:03.534670","exception":false,"start_time":"2025-08-03T20:17:03.511020","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load the data files","metadata":{"papermill":{"duration":0.011867,"end_time":"2025-08-03T20:17:03.558939","exception":false,"start_time":"2025-08-03T20:17:03.547072","status":"completed"},"tags":[]}},{"cell_type":"code","source":"bbcnews_train = pd.read_csv('/kaggle/input/learn-ai-bbc/BBC News Train.csv')\nbbcnews_test = pd.read_csv('/kaggle/input/learn-ai-bbc/BBC News Test.csv')\nsubmission_sample = pd.read_csv('/kaggle/input/learn-ai-bbc/BBC News Sample Solution.csv')","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:03:46.322954Z","start_time":"2025-08-02T17:03:46.206813Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:04.641746Z","iopub.execute_input":"2025-08-04T05:13:04.642019Z","iopub.status.idle":"2025-08-04T05:13:04.861136Z","shell.execute_reply.started":"2025-08-04T05:13:04.641997Z","shell.execute_reply":"2025-08-04T05:13:04.860154Z"},"papermill":{"duration":0.188051,"end_time":"2025-08-03T20:17:03.758689","exception":false,"start_time":"2025-08-03T20:17:03.570638","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 1. Exploratory Data Analysis (EDA)","metadata":{"papermill":{"duration":0.011425,"end_time":"2025-08-03T20:17:03.781879","exception":false,"start_time":"2025-08-03T20:17:03.770454","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### Examine data sets\n\nLet's take a look at the train, test, and sample submission data sets","metadata":{"papermill":{"duration":0.011265,"end_time":"2025-08-03T20:17:03.804895","exception":false,"start_time":"2025-08-03T20:17:03.793630","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f'Train data set: {bbcnews_train.shape}\\n')\nprint(bbcnews_train.info())\nbbcnews_train.head()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:03:49.809986Z","start_time":"2025-08-02T17:03:49.771662Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:04.863184Z","iopub.execute_input":"2025-08-04T05:13:04.863581Z","iopub.status.idle":"2025-08-04T05:13:04.916818Z","shell.execute_reply.started":"2025-08-04T05:13:04.863552Z","shell.execute_reply":"2025-08-04T05:13:04.915885Z"},"papermill":{"duration":0.070954,"end_time":"2025-08-03T20:17:03.887626","exception":false,"start_time":"2025-08-03T20:17:03.816672","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Test data set: {bbcnews_test.shape}\\n')\nprint(bbcnews_test.info())\nbbcnews_test.head()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:03:51.358728Z","start_time":"2025-08-02T17:03:51.346837Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:04.918082Z","iopub.execute_input":"2025-08-04T05:13:04.918480Z","iopub.status.idle":"2025-08-04T05:13:04.940601Z","shell.execute_reply.started":"2025-08-04T05:13:04.918447Z","shell.execute_reply":"2025-08-04T05:13:04.938139Z"},"papermill":{"duration":0.030839,"end_time":"2025-08-03T20:17:03.931270","exception":false,"start_time":"2025-08-03T20:17:03.900431","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Sample submission data set: {submission_sample.shape}\\n')\nsubmission_sample","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:03:52.547535Z","start_time":"2025-08-02T17:03:52.533366Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:04.942159Z","iopub.execute_input":"2025-08-04T05:13:04.942477Z","iopub.status.idle":"2025-08-04T05:13:04.980652Z","shell.execute_reply.started":"2025-08-04T05:13:04.942452Z","shell.execute_reply":"2025-08-04T05:13:04.979324Z"},"papermill":{"duration":0.027844,"end_time":"2025-08-03T20:17:03.971437","exception":false,"start_time":"2025-08-03T20:17:03.943593","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Confirmed that the training data has 1490 rows, containing no NaN/None/null values, and the following three columns:\n* ArticleId - Article id, unique # given to the record\n* Text - text of the header and article\n* Category - cateogry of the article (tech, business, sport, entertainment, politics)\n\nThe test set has 735 rows, containing no NaN/None/null values, with the ArticleId and Text data, without the Category label. This is the data set that will be used for the submission.\n\nThe sample submission format inclcudes only the ArticleId and predicted Category.","metadata":{"papermill":{"duration":0.079342,"end_time":"2025-08-03T20:17:04.064115","exception":false,"start_time":"2025-08-03T20:17:03.984773","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Explore distributions of data by category","metadata":{"papermill":{"duration":0.012241,"end_time":"2025-08-03T20:17:04.088827","exception":false,"start_time":"2025-08-03T20:17:04.076586","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# list categories and count for each\nbbcnews_train.groupby('Category').count()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:00.352753Z","start_time":"2025-08-02T17:04:00.334869Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:04.981713Z","iopub.execute_input":"2025-08-04T05:13:04.982070Z","iopub.status.idle":"2025-08-04T05:13:05.005553Z","shell.execute_reply.started":"2025-08-04T05:13:04.982038Z","shell.execute_reply":"2025-08-04T05:13:05.004397Z"},"papermill":{"duration":0.026275,"end_time":"2025-08-03T20:17:04.128070","exception":false,"start_time":"2025-08-03T20:17:04.101795","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Let's generate some visualizations","metadata":{"papermill":{"duration":0.013456,"end_time":"2025-08-03T20:17:04.156755","exception":false,"start_time":"2025-08-03T20:17:04.143299","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Plot the number of articles in each category\n\n# Get counts by categorry\ncategory_counts = bbcnews_train['Category'].value_counts()\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\nax = category_counts.plot(kind='bar', color='steelblue')\n\n# Add horizontal lines for mean and median\nmean_count = category_counts.mean()\nmedian_count = category_counts.median()\nax.axhline(y=mean_count, color='red', linestyle='--', linewidth=1.5, label=f'Mean: {mean_count:.1f}')\nax.axhline(y=median_count, color='green', linestyle=':', linewidth=1.5, label=f'Median: {median_count:.1f}')\n\nplt.title('Number of BBC News Articles by Category', fontsize=16)\nplt.xlabel('Category', fontsize=14)\nplt.ylabel('Number of Articles', fontsize=14)\nplt.xticks(rotation=45)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.legend()\n\n# Add the counts on top of each bar\nfor i, category_count in enumerate(category_counts):\n    plt.text(i, category_count + 5, str(category_count), ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:03.124598Z","start_time":"2025-08-02T17:04:02.800478Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:05.006907Z","iopub.execute_input":"2025-08-04T05:13:05.007201Z","iopub.status.idle":"2025-08-04T05:13:05.500838Z","shell.execute_reply.started":"2025-08-04T05:13:05.007177Z","shell.execute_reply":"2025-08-04T05:13:05.499728Z"},"papermill":{"duration":0.480977,"end_time":"2025-08-03T20:17:04.651357","exception":false,"start_time":"2025-08-03T20:17:04.170380","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Distribution of article length by category\n\n# Calculate the length for each article\nbbcnews_train['text_length'] = bbcnews_train['Text'].apply(len)\n\n# Create a box plot to compare text length by category\ncategory_colors = {\n    'business': '#1f77b4',      # blue\n    'entertainment': '#ff7f0e', # orange\n    'politics': '#2ca02c',      # green\n    'sport': '#d62728',         # red\n    'tech': '#9467bd'           # purple\n}\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='Category', y='text_length', data=bbcnews_train, palette=category_colors, hue='Category')\nplt.title('Distribution of Text Length by Category', fontsize=14)\nplt.xlabel('Category', fontsize=12)\nplt.ylabel('Text Length (characters)', fontsize=12)\nplt.grid(axis='y', alpha=0.3)\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:05.808215Z","start_time":"2025-08-02T17:04:05.377888Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:05.501951Z","iopub.execute_input":"2025-08-04T05:13:05.502336Z","iopub.status.idle":"2025-08-04T05:13:05.893260Z","shell.execute_reply.started":"2025-08-04T05:13:05.502274Z","shell.execute_reply":"2025-08-04T05:13:05.892043Z"},"papermill":{"duration":0.361851,"end_time":"2025-08-03T20:17:05.027668","exception":false,"start_time":"2025-08-03T20:17:04.665817","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the distribution of word counts\n\n# Calculate the word count for each article\nbbcnews_train['word_count'] = bbcnews_train['Text'].apply(lambda x: len(str(x).split()))\n\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='Category', y='word_count', data=bbcnews_train, palette=category_colors, hue='Category')\nplt.title('Distribution of Word Count by Category', fontsize=14)\nplt.xlabel('Category', fontsize=12)\nplt.ylabel('Word Count', fontsize=12)\nplt.grid(axis='y', alpha=0.3)\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:08.404902Z","start_time":"2025-08-02T17:04:08.159214Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:05.897719Z","iopub.execute_input":"2025-08-04T05:13:05.898098Z","iopub.status.idle":"2025-08-04T05:13:06.316559Z","shell.execute_reply.started":"2025-08-04T05:13:05.898073Z","shell.execute_reply":"2025-08-04T05:13:06.315414Z"},"papermill":{"duration":0.397818,"end_time":"2025-08-03T20:17:05.440463","exception":false,"start_time":"2025-08-03T20:17:05.042645","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Let's explore the distribution of words across all articles","metadata":{"papermill":{"duration":0.015284,"end_time":"2025-08-03T20:17:05.471979","exception":false,"start_time":"2025-08-03T20:17:05.456695","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# The the distribution of the word count for all articles\nplt.figure(figsize=(12, 8))\n\n# Create the histogram of word counts\nbins = np.linspace(0, bbcnews_train['word_count'].max(), 100)\nn, bins, patches = plt.hist(bbcnews_train['word_count'], bins=bins,\n                            color='#3498db', alpha=0.8, edgecolor='white', linewidth=0.5)\n\n# Calculate statistics\nmean_val = bbcnews_train['word_count'].mean()\nmedian_val = bbcnews_train['word_count'].median()\nmode_val = bbcnews_train['word_count'].mode()[0]\nstd_val = bbcnews_train['word_count'].std()\n\n# Add vertical lines for mean and median (with thinner lines)\nplt.axvline(x=mean_val, color='red', linestyle='--', linewidth=0.8, label=f'Mean: {mean_val:.0f}')\nplt.axvline(x=median_val, color='green', linestyle=':', linewidth=0.8, label=f'Median: {median_val:.0f}')\n\nplt.title('Distribution of Word Counts in BBC News Articles', fontsize=16, pad=20)\nplt.xlabel('Word Count', fontsize=14, labelpad=10)\nplt.ylabel('Frequency', fontsize=14, labelpad=10)\nplt.grid(axis='y', alpha=0.3, linestyle='--')\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.legend(fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n# Associated boxplot for the word count distribution\nplt.figure(figsize=(12, 4))\nax = sns.boxplot(x=bbcnews_train['word_count'], color='#3498db')\n\n# Calculate and display whisker values\nQ1 = bbcnews_train['word_count'].quantile(0.25)\nQ3 = bbcnews_train['word_count'].quantile(0.75)\nIQR = Q3 - Q1\nlower_whisker = Q1 - 1.5 * IQR\nupper_whisker = Q3 + 1.5 * IQR\n\n# Text annotations\nplt.text(upper_whisker, -0.3, f'Max Normal: {upper_whisker:.0f}', ha='center', va='bottom', fontweight='bold')  # plot upper whisker\nplt.title('Boxplot of Word Counts', fontsize=16, pad=20)\nplt.xlabel('Word Count', fontsize=14, labelpad=10)\nplt.grid(axis='x', alpha=0.3, linestyle='--')\nplt.tight_layout()\nplt.show()\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:12.137095Z","start_time":"2025-08-02T17:04:11.637178Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:06.318490Z","iopub.execute_input":"2025-08-04T05:13:06.318764Z","iopub.status.idle":"2025-08-04T05:13:06.999318Z","shell.execute_reply.started":"2025-08-04T05:13:06.318743Z","shell.execute_reply":"2025-08-04T05:13:06.998333Z"},"papermill":{"duration":0.656142,"end_time":"2025-08-03T20:17:06.143930","exception":false,"start_time":"2025-08-03T20:17:05.487788","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The data looks to have some significant outliers, where the number of words in some articles exceed the max normal of 792. Given that these are news articles, a general principle in jouranlism is to provide the most newsworthy information (who, what, when, where, why) towards the beginning of the article (inverted pyramid structure). Based on this principle, we can likely truncate the longer articles and still retain the necessary text to categorize it appropriately. We can play with some options and compare the results.","metadata":{"papermill":{"duration":0.017615,"end_time":"2025-08-03T20:17:06.181615","exception":false,"start_time":"2025-08-03T20:17:06.164000","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Check for duplicates","metadata":{"papermill":{"duration":0.01782,"end_time":"2025-08-03T20:17:06.218917","exception":false,"start_time":"2025-08-03T20:17:06.201097","status":"completed"},"tags":[]}},{"cell_type":"code","source":"bbcnews_train.nunique()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:16.867653Z","start_time":"2025-08-02T17:04:16.853163Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.000491Z","iopub.execute_input":"2025-08-04T05:13:07.001012Z","iopub.status.idle":"2025-08-04T05:13:07.020935Z","shell.execute_reply.started":"2025-08-04T05:13:07.000977Z","shell.execute_reply":"2025-08-04T05:13:07.019835Z"},"papermill":{"duration":0.041847,"end_time":"2025-08-03T20:17:06.279593","exception":false,"start_time":"2025-08-03T20:17:06.237746","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It looks like we have 50 articles where the text is not unique. Let's explore that further.","metadata":{"papermill":{"duration":0.017604,"end_time":"2025-08-03T20:17:06.315090","exception":false,"start_time":"2025-08-03T20:17:06.297486","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Find duplicate rows in the training dataset where 'Text' is not unique\ntrain_duplicates = bbcnews_train[bbcnews_train.duplicated(subset=['Text'], keep=False)]\nprint(f\"Number of duplicate rows: {len(train_duplicates)}\")\ndisplay(train_duplicates.sort_values(by='Text'))\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:19.207301Z","start_time":"2025-08-02T17:04:19.192703Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.021925Z","iopub.execute_input":"2025-08-04T05:13:07.022164Z","iopub.status.idle":"2025-08-04T05:13:07.043056Z","shell.execute_reply.started":"2025-08-04T05:13:07.022146Z","shell.execute_reply":"2025-08-04T05:13:07.041798Z"},"papermill":{"duration":0.039898,"end_time":"2025-08-03T20:17:06.372913","exception":false,"start_time":"2025-08-03T20:17:06.333015","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's verify that articles with identical text is also labeled with the same category","metadata":{"papermill":{"duration":0.018374,"end_time":"2025-08-03T20:17:06.409506","exception":false,"start_time":"2025-08-03T20:17:06.391132","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Group duplicates by Text and check if all rows in each group have the same Category\nprint(\"Analysis of duplicate texts in training dataset:\")\nfor text_with_dups, text_categories in train_duplicates.groupby('Text'):\n    dup_categories = text_categories['Category'].unique()\n    if len(dup_categories) == 1:\n        print(f\"Text (truncated): '{text_with_dups[:50]}...' has {len(text_categories)} duplicates, all with category: {dup_categories[0]}\")\n    else:\n        print(f\"Text (truncated): '{text_with_dups[:50]}...' has {len(text_categories)} duplicates with different categories: {dup_categories}\")\n\n# Count how many duplicate texts have consistent vs inconsistent categories\nsame_category = 0\ndifferent_category = 0\n\nfor dup_text, dup_cat in train_duplicates.groupby('Text'):\n    if len(dup_cat['Category'].unique()) == 1:\n        same_category += 1\n    else:\n        different_category += 1\n\nprint(f\"\\nSummary:\")\nprint(f\"- Duplicate texts with the same category: {same_category}\")\nprint(f\"- Duplicate texts with different categories: {different_category}\")","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:22.303689Z","start_time":"2025-08-02T17:04:22.284178Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.044229Z","iopub.execute_input":"2025-08-04T05:13:07.044561Z","iopub.status.idle":"2025-08-04T05:13:07.218162Z","shell.execute_reply.started":"2025-08-04T05:13:07.044537Z","shell.execute_reply":"2025-08-04T05:13:07.216719Z"},"papermill":{"duration":0.041074,"end_time":"2025-08-03T20:17:06.469441","exception":false,"start_time":"2025-08-03T20:17:06.428367","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We found no article text duplicates with different categories, so we should just remove the duplicates. Let's take a quick look at the structure of an article.","metadata":{"papermill":{"duration":0.018343,"end_time":"2025-08-03T20:17:06.506156","exception":false,"start_time":"2025-08-03T20:17:06.487813","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f\"Article[0]: {bbcnews_train['Text'][0]}\\n\")\nprint(f\"Article[1]: {bbcnews_train['Text'][1]}\\n\")","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:26.174010Z","start_time":"2025-08-02T17:04:26.167291Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.218899Z","iopub.execute_input":"2025-08-04T05:13:07.219209Z","iopub.status.idle":"2025-08-04T05:13:07.225945Z","shell.execute_reply.started":"2025-08-04T05:13:07.219186Z","shell.execute_reply":"2025-08-04T05:13:07.224641Z"},"papermill":{"duration":0.026094,"end_time":"2025-08-03T20:17:06.550515","exception":false,"start_time":"2025-08-03T20:17:06.524421","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analysis Plan\n\nBased on the findings from the EDA analysis, we will perform the following actions in the preprocessing steps:\n\n1. Delete duplicate rows,\n2. Enable word count truncation limits within the text cleanup process,\n3. Convert to lowercase (even though the viewed articles are already lowercase),\n4. Remove punctuation,\n5. Remove numbers/digits,\n6. Remove standard english stopwords\n7. Evaluate removing short words (length < 3 chars)\n\n#### Unsupervised model\n\nSince the unsupervised model, Non-negative Matrix Factorization (NMF), has been predetermined for the initial evaluation, we only plan to focus on the following aspects for tuning the prediction accuracy:\n\n* Text Preprocessing - testing different options for tokenization and normalization (e.g., stemming/lemmatizing)\n* Vectorizing - for this project we are vectorizing using the TD-IDF vectorizer\n* Hyperparameter tuning - the project will leverage GridSearchCV to determine target hyperparameters for the final model\n\n#### Supervised model\n\nThe final steps in the project will be to evaluate and select a supervised model to classify the category and then compare the results with the unsupervised approach. GridSearchCV will again be used to evaluate the different models and then tune the final supervised model. The following supervised learning models will be evaluated:\n\n* Random Forests\n* SVM (LinearSVC)\n* LogisticRegression\n","metadata":{"papermill":{"duration":0.018316,"end_time":"2025-08-03T20:17:06.592959","exception":false,"start_time":"2025-08-03T20:17:06.574643","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Step 1b. Data Preprocessing","metadata":{"papermill":{"duration":0.01969,"end_time":"2025-08-03T20:17:06.631306","exception":false,"start_time":"2025-08-03T20:17:06.611616","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Remove ~50 articles with duplicated text","metadata":{"papermill":{"duration":0.018382,"end_time":"2025-08-03T20:17:06.668043","exception":false,"start_time":"2025-08-03T20:17:06.649661","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# remove duplicates\nbbcnews_train = bbcnews_train.drop_duplicates(subset = ['Text'], keep = 'first')\nremaining_dups = bbcnews_train[bbcnews_train.duplicated(subset=['Text'], keep=False)]\nprint(f\"Remaining duplicates in the training dataset: {len(remaining_dups)}\")","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:31.840688Z","start_time":"2025-08-02T17:04:31.831254Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.227063Z","iopub.execute_input":"2025-08-04T05:13:07.227476Z","iopub.status.idle":"2025-08-04T05:13:07.255638Z","shell.execute_reply.started":"2025-08-04T05:13:07.227450Z","shell.execute_reply":"2025-08-04T05:13:07.254635Z"},"papermill":{"duration":0.030824,"end_time":"2025-08-03T20:17:06.718185","exception":false,"start_time":"2025-08-03T20:17:06.687361","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### TextCleaner\n\nCreate a custom transformer to perform the cleaning, vectorization, and normalization functions on the article text. Using a custom transformer for the text cleanup enables use within a pipeline process. The text cleanup function supports the following Text Preprocessing methods:\n* Simple Tokenization - split text into words\n* spaCy Lemmitizer - spaCy library for tokenization and lemmatizing\n* WordNet Lemmatizer - Simple tokenization with NLTK WordNet lemmatizing using part of speech (POS) tagging\n* Snowball Stemmer - Simple tokenization with NLTK Snowball stemming","metadata":{"papermill":{"duration":0.028109,"end_time":"2025-08-03T20:17:06.768939","exception":false,"start_time":"2025-08-03T20:17:06.740830","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a custom transformer to perform text cleanup (usable in pipeline later)\nclass TextCleaner(BaseEstimator, TransformerMixin):\n    def __init__(self, min_word_length=2, max_word_count=0, method='simple', additional_words=None, stop_words=None):\n        self.min_word_length = min_word_length\n        self.max_word_count = max_word_count\n        self.method = method\n        self.additional_words = additional_words\n        self.stop_words = stop_words\n\n    def __getstate__(self):\n        # Return state for pickling, excluding unpickleable objects\n        state = self.__dict__.copy()\n        return state\n\n    def __setstate__(self, state):\n        # Restore state from pickle\n        self.__dict__.update(state)\n        # Recreate remove_words_ if it exists\n        if hasattr(self, 'remove_words_'):\n            self._create_remove_words()\n\n    # empty fit function to support use in pipeline\n    def fit(self, X, y=None):\n        # Initialize the remove_words set when fitting\n        self._create_remove_words()\n        return self\n\n    # transform function for _cleanup_text to support use in pipeline\n    def transform(self, X):\n        if not hasattr(self, 'remove_words_'):\n            self._create_remove_words()\n\n        if hasattr(X, 'apply'):\n            return X.copy().apply(self._cleanup_text)\n        else:\n            return [self._cleanup_text(text) for text in X]\n\n    # function to generate the remove_words_ set\n    def _create_remove_words(self):\n        # Create a local stop_words variable - don't modify self.stop_words\n        if self.stop_words is None:\n            stop_words = set(stopwords.words('english'))\n        else:\n            stop_words = set(self.stop_words)\n\n        if self.additional_words:\n            # Convert to list first, then back to set to avoid pickle issues\n            combined = list(stop_words) + list(self.additional_words)\n            self.remove_words_ = set(combined)\n        else:\n            self.remove_words_ = stop_words\n\n    # Function to perform the text cleanup and stem/lemmatize as specified\n    def _cleanup_text(self, text):\n        # Convert to lowercase\n        text = text.lower()\n\n        # Remove punctuation\n        text = re.sub(r'[^\\w\\s]', ' ', text)\n\n        # Remove numbers\n        text = re.sub(r'\\d+', ' ', text)\n\n        # Process words (lemmatize, removing stopwords and additional words supplied, short words, and extra spaces)\n        match self.method:\n            case 'wordnet':\n                words = self._wordnet_lemma(text)\n            case 'snowball':\n                words = self._snowball_stemmer(text)\n            case _:  # default to 'simple'\n                words = self._simple_tokens(text)\n\n        # Limit to max word count if specified\n        if self.max_word_count > 0:\n            words = words[:self.max_word_count]\n\n        return ' '.join(words)\n\n    # Simple word tokens, removing words in the remove_words list and short words\n    def _simple_tokens(self, text):\n        tokens = text.split()\n        return [token for token in tokens if token not in self.remove_words_ and len(token) > self.min_word_length]\n\n    # WordNetLemmatizer\n    def _get_wordnet_pos(self, nltk_tag):\n        # Map for most common matches on the first letter of the tag\n        pos_map = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'J': wordnet.ADJ, 'R': wordnet.ADV}\n\n        # Map NLTK POS tags to WordNet POS tags\n        if nltk_tag[0] in pos_map:\n            return pos_map[nltk_tag[0]]\n        elif nltk_tag in ('MD', 'TO'):  # Modal, infinitive marker\n            return wordnet.VERB\n        else:\n             return wordnet.NOUN  # Default to Noun for other cases\n\n    def _wordnet_lemma(self, text):\n        # NLTK data needed for wordnet and pos_tag - see Imports\n        lemmatizer = WordNetLemmatizer()\n        tokens = self._simple_tokens(text)\n\n        # Get POS (part of speech) tags\n        tagged_tokens = pos_tag(tokens)\n\n        # Lemmatize with POS tag\n        lemmatized_words = []\n        for word, tag in tagged_tokens:\n            if word not in self.remove_words_ and len(word) > self.min_word_length:\n                # Get the WordNet POS tag\n                wordnet_pos = self._get_wordnet_pos(tag)\n\n                # Lemmatize with the appropriate POS tag\n                lemma = lemmatizer.lemmatize(word, wordnet_pos)\n                lemmatized_words.append(lemma)\n\n        return lemmatized_words\n\n    # SnowballStemmer\n    def _snowball_stemmer(self, text):\n        stemmer = SnowballStemmer(\"english\")\n        tokens = self._simple_tokens(text)\n\n        # apply stemming\n        words = [stemmer.stem(word) for word in tokens]\n\n        return words\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:35.791527Z","start_time":"2025-08-02T17:04:35.779394Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.256708Z","iopub.execute_input":"2025-08-04T05:13:07.256972Z","iopub.status.idle":"2025-08-04T05:13:07.287532Z","shell.execute_reply.started":"2025-08-04T05:13:07.256951Z","shell.execute_reply":"2025-08-04T05:13:07.286010Z"},"papermill":{"duration":0.046891,"end_time":"2025-08-03T20:17:06.846370","exception":false,"start_time":"2025-08-03T20:17:06.799479","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Quick evaluation on word tokenization\n\nUsing the TextCleaner transformer, we are going to perform a quick evaluation to see if there are any common words across all groups that could impact categorization","metadata":{"papermill":{"duration":0.018439,"end_time":"2025-08-03T20:17:06.883470","exception":false,"start_time":"2025-08-03T20:17:06.865031","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Cleanup the article Text - default simple method\ntext_cleaner = TextCleaner(method = 'simple')\nbbcnews_train['Text_cleaned'] = text_cleaner.transform(bbcnews_train['Text'])\nprint(\"Original Text: \", bbcnews_train['Text'][0], \"\\n\\n\")\nprint(\"Cleaned Text: \", bbcnews_train['Text_cleaned'][0])","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:40.597687Z","start_time":"2025-08-02T17:04:40.396110Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.288771Z","iopub.execute_input":"2025-08-04T05:13:07.289082Z","iopub.status.idle":"2025-08-04T05:13:07.580885Z","shell.execute_reply.started":"2025-08-04T05:13:07.289057Z","shell.execute_reply":"2025-08-04T05:13:07.579707Z"},"papermill":{"duration":0.285114,"end_time":"2025-08-03T20:17:07.189092","exception":false,"start_time":"2025-08-03T20:17:06.903978","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's find the most common words in each category, then across all categories","metadata":{}},{"cell_type":"code","source":"# Find most common words in each category and across categories\n\n# Helper function to get the top N words from a category\ndef get_top_n_words(category, top_n=30):\n    # Get the articles for the specified category\n    category_data = bbcnews_train[bbcnews_train['Category'] == category]\n\n    # Combine all cleaned text for this category\n    all_words = ' '.join(category_data['Text_cleaned']).split()\n\n    # Count word frequencies and get the top N\n    top_words = Counter(all_words).most_common(top_n)\n\n    return top_words\n\n\ndef get_top_m_common_words(top_m=30, top_n=100, sort_by='average'):\n    # Get the top_n words for each category\n    categories = bbcnews_train['Category'].unique()\n    category_words = {}\n    for category in categories:\n        category_words[category] = dict(get_top_n_words(category, top_n))\n\n    # Find common words in all categories\n    common_words = set(category_words[categories[0]].keys())\n    for category in categories[1:]:\n        common_words = common_words.intersection(set(category_words[category].keys()))\n\n    print(f\"The number of common words in all categories is {len(common_words)}\")\n\n    # Get the counts for each word\n    # Create a DataFrame with counts for each word in each category\n    data = []\n    for word in common_words:\n        row = {'word': word}\n        counts = []\n        for cat in categories:\n            count = category_words[cat][word]\n            row[cat] = count\n            counts.append(count)\n\n        # Calculate statistics\n        row['total_count'] = sum(counts)\n        row['avg_count'] = np.mean(counts)\n        row['min_count'] = min(counts)\n        row['max_count'] = max(counts)\n        row['std_dev'] = np.std(counts)\n        row['cv'] = row['std_dev'] / row['avg_count'] if row['avg_count'] > 0 else 0  # Coefficient of variation\n\n        data.append(row)\n    result_df = pd.DataFrame(data)\n\n    # Sort based on the specified method\n    match sort_by:\n        case 'total':\n            result_df = result_df.sort_values('total_count', ascending=False)\n        case 'min_count':\n            result_df = result_df.sort_values('min_count', ascending=False)\n        case 'consistency':\n            result_df = result_df.sort_values('cv', ascending=True)  # Lower CV means more consistent across categories\n        case _:  # default to 'average'\n            result_df = result_df.sort_values('avg_count', ascending=False)\n\n    result_df = result_df.reset_index(drop=True)\n\n    # Return top m common words\n    return result_df.head(top_m)\n\n\ncommon_category_words = get_top_m_common_words(top_n=30)\ndisplay(common_category_words)","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:44.472162Z","start_time":"2025-08-02T17:04:44.390093Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.581770Z","iopub.execute_input":"2025-08-04T05:13:07.582011Z","iopub.status.idle":"2025-08-04T05:13:07.687852Z","shell.execute_reply.started":"2025-08-04T05:13:07.581991Z","shell.execute_reply":"2025-08-04T05:13:07.686944Z"},"papermill":{"duration":0.118825,"end_time":"2025-08-03T20:17:07.326771","exception":false,"start_time":"2025-08-03T20:17:07.207946","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Word Treemaps for each Category\n\nLet's create word treemaps for each category to visualize the most common. We'll create a helper function to create the treemap and default to the top 30 words and iterate through each category passed.","metadata":{}},{"cell_type":"code","source":"# Create and display treemaps for the top words in each category\n\n# Helper function to create treemaps for each category using squarify, since Plotly Express treemaps weren't displaying on Run\ndef create_category_treemaps(category_list, top_n=30):\n    color_schemes = {\n        'business': 'Blues',\n        'entertainment': 'BuGn',\n        'politics': 'Greens',\n        'sport': 'Reds', \n        'tech': 'Purples'\n    }\n    \n    # Create figure with space for colorbars\n    fig = plt.figure(figsize=(14, 20))\n    \n    for i, category in enumerate(category_list):\n        ax = plt.subplot(5, 1, i+1)  # create a 5 row, single column plot\n        \n        # Get data\n        treemap_data = pd.DataFrame(get_top_n_words(category, top_n), columns=['word', 'count'])\n        sizes = treemap_data['count'].tolist()\n        labels = treemap_data['word'].tolist()\n        \n        # Create colors (fix deprecated get_cmap)\n        cmap = plt.colormaps[color_schemes.get(category, 'Blues')]\n        norm = mcolors.Normalize(vmin=min(sizes), vmax=max(sizes))\n        colors = [cmap(norm(size)) for size in sizes]\n        \n        # Create treemap (remove alignment parameters to avoid conflicts)\n        sqrf.plot(\n            sizes=sizes,\n            label=[f\"{label}\\n{size}\" for label, size in zip(labels, sizes)],  # Include counts\n            alpha=1.0,\n            color=colors,\n            ax=ax,\n            pad=0,\n            text_kwargs={\n                'fontsize': 9,\n                # 'fontweight': 'normal'\n            },\n            # borders between squares\n            bar_kwargs={\n                'linewidth': 0.3,\n                'edgecolor': 'black'\n            }\n        )\n        \n        # Update text colors to get appropriate white/black depending on darkness\n        texts = ax.texts\n        patches = ax.patches\n        \n        # Match texts to patches by index\n        for idx, text_obj in enumerate(texts):\n            if idx < len(colors):\n                patch_color = colors[idx]\n                \n                # Calculate brightness using the RGB values\n                r, g, b = patch_color[0], patch_color[1], patch_color[2]\n                brightness = (r * 0.299 + g * 0.587 + b * 0.114)\n                \n                # Use white text on dark colors, black on light colors\n                if brightness < 0.6:\n                    text_obj.set_color('white')\n                    # text_obj.set_weight('bold')  # Make white text bold for better visibility\n                else:\n                    text_obj.set_color('black')\n        \n        # Style subplot\n        ax.axis('off')\n        ax.set_title(f'Most Common Words in {category.capitalize()} Articles', fontsize=12, fontweight='bold', pad=15)\n        \n        # Add colorbar\n        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n        sm.set_array([])\n        \n        # Position colorbar to the right of each subplot\n        pos = ax.get_position()\n        cbar_ax = fig.add_axes([pos.x1 + 0.02, pos.y0, 0.02, pos.height])\n        cbar = plt.colorbar(sm, cax=cbar_ax)\n        cbar.set_label('Count', rotation=270, labelpad=15, fontsize=10)\n    \n    return fig","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:49.790509Z","start_time":"2025-08-02T17:04:47.262435Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:07.688872Z","iopub.execute_input":"2025-08-04T05:13:07.689157Z","iopub.status.idle":"2025-08-04T05:13:09.429706Z","shell.execute_reply.started":"2025-08-04T05:13:07.689134Z","shell.execute_reply":"2025-08-04T05:13:09.428016Z"},"papermill":{"duration":2.83776,"end_time":"2025-08-03T20:17:10.184404","exception":false,"start_time":"2025-08-03T20:17:07.346644","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize the word treemap for each category \ntreemap_fig = create_category_treemaps(bbcnews_train['Category'].unique())\ntreemap_fig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T16:47:39.806940Z","iopub.execute_input":"2025-08-04T16:47:39.807698Z","iopub.status.idle":"2025-08-04T16:47:39.902696Z","shell.execute_reply.started":"2025-08-04T16:47:39.807669Z","shell.execute_reply":"2025-08-04T16:47:39.901480Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Remove Common Words\n\nLooking at the six common words across all categories (said, would, year, also, new, one), and their prevalence within the top words, we will remove them from the text along with the standard stop words.","metadata":{"papermill":{"duration":0.019598,"end_time":"2025-08-03T20:17:10.224718","exception":false,"start_time":"2025-08-03T20:17:10.205120","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Remove the common words from the word list\nremove_common = common_category_words['word'].tolist()\n\n# Cleanup the article Text\ntext_cleaner = TextCleaner(additional_words=remove_common)\nbbcnews_train['Text_cleaned'] = text_cleaner.transform(bbcnews_train['Text'])\n\n# Visualize the word treemaps with the common words removed\ntreemap_fig = create_category_treemaps(bbcnews_train['Category'].unique())\ntreemap_fig.show()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:04:55.486961Z","start_time":"2025-08-02T17:04:54.278786Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:09.430555Z","iopub.execute_input":"2025-08-04T05:13:09.430866Z","iopub.status.idle":"2025-08-04T05:13:11.963662Z","shell.execute_reply.started":"2025-08-04T05:13:09.430840Z","shell.execute_reply":"2025-08-04T05:13:11.961898Z"},"papermill":{"duration":0.642305,"end_time":"2025-08-03T20:17:10.887133","exception":false,"start_time":"2025-08-03T20:17:10.244828","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The word treemaps look better without the common words, especially given 'said' was the top word across all categories","metadata":{"papermill":{"duration":0.022092,"end_time":"2025-08-03T20:17:10.931380","exception":false,"start_time":"2025-08-03T20:17:10.909288","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Step 1c. Create training and test data sets","metadata":{"papermill":{"duration":0.021669,"end_time":"2025-08-03T20:17:10.974979","exception":false,"start_time":"2025-08-03T20:17:10.953310","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Split the current Train data set into a train and test sets to evaluate the models\nX_train, X_test, y_train, y_test = train_test_split(\n    bbcnews_train.Text,\n    bbcnews_train.Category,\n    test_size=0.2,\n    random_state=42,\n    stratify=bbcnews_train.Category  # Maintain class distribution\n)\nX_train.head()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:05:00.338647Z","start_time":"2025-08-02T17:05:00.324849Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:11.965079Z","iopub.execute_input":"2025-08-04T05:13:11.965465Z","iopub.status.idle":"2025-08-04T05:13:11.984913Z","shell.execute_reply.started":"2025-08-04T05:13:11.965434Z","shell.execute_reply":"2025-08-04T05:13:11.983208Z"},"papermill":{"duration":0.040119,"end_time":"2025-08-03T20:17:11.037754","exception":false,"start_time":"2025-08-03T20:17:10.997635","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2. Building and training the unsupervised model","metadata":{"papermill":{"duration":0.022126,"end_time":"2025-08-03T20:17:11.082451","exception":false,"start_time":"2025-08-03T20:17:11.060325","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Create a helper function to match prediction scores with category labels.  (re-using a function from a previous class module with some modification for the inital lable order and data types)","metadata":{"papermill":{"duration":0.022312,"end_time":"2025-08-03T20:17:11.127470","exception":false,"start_time":"2025-08-03T20:17:11.105158","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Helper function to match categories with NMF results\ndef label_permute_compare(yt, yp, labels):\n    # To support use in GridSearchCV/pipeline, need to handle the passed data formats\n    # Make sure yt is a numpy array\n    if isinstance(yt, pd.DataFrame):\n        # Original data is a DataFrame input\n        ytlist = yt.iloc[:, 0].to_numpy()\n    elif isinstance(yt, pd.Series):\n        # Cross-validation passes Series\n        ytlist = yt.to_numpy()\n    elif hasattr(yt, '__iter__') and not isinstance(yt, str):\n        # List, array, or other iterable\n        ytlist = np.array(list(yt))\n    else:\n        # Single value\n        ytlist = np.array([yt])\n\n    # Make sure yp is a numpy array)\n    if isinstance(yp, pd.Series):\n        yp = yp.to_numpy()\n    elif not isinstance(yp, np.ndarray):\n        yp = np.array(yp)\n\n    # Both arrays should have the same length\n    if len(ytlist) != len(yp):\n        raise ValueError(f\"yt (y_true) and yp (y_pred) must have same length. Got {len(ytlist)} and {len(yp)}\")\n\n    # Create permutations - only use as many as we have unique predicted values\n    unique_predictions = len(np.unique(yp))\n    labels_to_use = labels[:unique_predictions] if len(labels) >= unique_predictions else labels\n\n    # Create a list of permutations for the labels\n    perms = [list(perm) for perm in itertools.permutations(labels_to_use, len(labels_to_use))]\n\n    # iterate through the permutations and calculate accuracy\n    label_acc = []\n    for perm in perms:\n        try:\n            # Create an array of labels for the prediction, using the permutation list and the cluster number as the index\n            yp_labels = np.array(perm)[yp]\n            # Get the accuracy score using the ground truth labels against this iteration of prediction labels\n            accuracy = accuracy_score(ytlist, yp_labels)\n            label_acc.append((accuracy, perm))\n        except IndexError as e:\n            # Handle case where yp has values outside the range of perm\n            print(f\"Warning: IndexError with permutation {perm}: {e}\")\n            continue\n\n    # Handle issue with permutations\n    if not label_acc:\n        print(\"Warning: No valid permutations found, returning 0 accuracy\")\n        return tuple(range(len(labels))), 0.0\n\n    # Get the results with the highest accuracy\n    best_accuracy = max(label_acc, key=lambda x: x[0])\n\n    # Map the best label order back to the original labels list for the permuted label order\n    try:\n        indices = [labels.index(label) for label in best_accuracy[1]]\n        return tuple(indices), best_accuracy[0]\n    except ValueError as e:\n        print(f\"Warning: Could not find all labels in original list: {e}\")\n        # Return default indices if mapping fails\n        return tuple(range(len(best_accuracy[1]))), best_accuracy[0]\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T22:06:24.288183Z","start_time":"2025-08-02T22:06:24.279823Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:11.985797Z","iopub.execute_input":"2025-08-04T05:13:11.986044Z","iopub.status.idle":"2025-08-04T05:13:12.012958Z","shell.execute_reply.started":"2025-08-04T05:13:11.986025Z","shell.execute_reply":"2025-08-04T05:13:12.011619Z"},"papermill":{"duration":0.040467,"end_time":"2025-08-03T20:17:11.191540","exception":false,"start_time":"2025-08-03T20:17:11.151073","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the pipeline for the process with an initial configuration for the text tokenizer, TF-IDF vectorizer, and NMF model.","metadata":{"papermill":{"duration":0.02281,"end_time":"2025-08-03T20:17:11.237537","exception":false,"start_time":"2025-08-03T20:17:11.214727","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a pipeline to clean, transform, and vectorize the text and perform NMF\ntext_cleaner_simple = TextCleaner(method='simple', max_word_count=792, additional_words=remove_common)\n\ntfidf_vectorizer = TfidfVectorizer(\n    min_df=5,\n    max_df=0.95,\n    analyzer='word',\n    ngram_range=(1, 2),\n    sublinear_tf=True,\n    token_pattern=r'\\b\\w+\\b'\n)\n\nnmf_model = NMF(\n    n_components=5,\n    random_state=42,\n    max_iter=300,\n    solver='cd',\n    beta_loss='frobenius',\n    alpha_H=0.0,\n    l1_ratio=0.5,\n    init='nndsvd'\n)\n\nnmf_pipeline = Pipeline([\n    ('text_cleaner', text_cleaner_simple),\n    ('tfidf', tfidf_vectorizer),\n    ('nmf', nmf_model)\n])","metadata":{"ExecuteTime":{"end_time":"2025-08-02T22:07:29.089292Z","start_time":"2025-08-02T22:07:29.084155Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:12.014565Z","iopub.execute_input":"2025-08-04T05:13:12.014950Z","iopub.status.idle":"2025-08-04T05:13:12.047050Z","shell.execute_reply.started":"2025-08-04T05:13:12.014911Z","shell.execute_reply":"2025-08-04T05:13:12.045930Z"},"papermill":{"duration":0.032477,"end_time":"2025-08-03T20:17:11.292946","exception":false,"start_time":"2025-08-03T20:17:11.260469","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Perform an initial run of the pipeline and check the resutls","metadata":{"papermill":{"duration":0.022331,"end_time":"2025-08-03T20:17:11.337625","exception":false,"start_time":"2025-08-03T20:17:11.315294","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Clean, transform, vectorize, and fit the article text\ny_hat_train = nmf_pipeline.fit_transform(X_train)\n\n# Assign the dominant topic as the prediction\ny_pred = y_hat_train.argmax(axis=1)\n\n# Extract and display topics\nprint(\"\\nTopics extracted from training data (top 10 words):\")\nfeature_names = nmf_pipeline.named_steps['tfidf'].get_feature_names_out()\nfor topic_idx, topic in enumerate(nmf_pipeline.named_steps['nmf'].components_):\n    top_10_words_idx = topic.argsort()[:-11:-1]  # Get indices of top 10 words\n    top_10_words = [feature_names[i] for i in top_10_words_idx]\n    print(f\"Topic #{topic_idx}: {' '.join(top_10_words)}\")\nprint(\"\\n\")\n\n# Get the category permutation mapping that achieves the highest accuracy for the clusters\nbase_category_list = np.unique(y_train).tolist()\ntopic_to_category_idx, accuracy = label_permute_compare(y_train, y_pred, base_category_list)\nprint(f\"Train Accuracy: {accuracy:.4f}\")\n\n# Map the predicted topics to category names from the permutation results\ncategory_mapping = {i: base_category_list[idx] for i, idx in enumerate(topic_to_category_idx)}\n\n# Convert the topic numbers to category names\npredicted_categories = [category_mapping[topic] for topic in y_pred]\n\n# Create confusion matrix\ncm = confusion_matrix(y_train, predicted_categories)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=base_category_list, yticklabels=base_category_list)\nplt.title('Confusion Matrix')\nplt.ylabel('True Category')\nplt.xlabel('Predicted Category')\nplt.tight_layout()\nplt.show()\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T22:07:31.744488Z","start_time":"2025-08-02T22:07:30.830045Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:12.048271Z","iopub.execute_input":"2025-08-04T05:13:12.048908Z","iopub.status.idle":"2025-08-04T05:13:13.828721Z","shell.execute_reply.started":"2025-08-04T05:13:12.048881Z","shell.execute_reply":"2025-08-04T05:13:13.827364Z"},"papermill":{"duration":1.637158,"end_time":"2025-08-03T20:17:12.998498","exception":false,"start_time":"2025-08-03T20:17:11.361340","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Setup GridSearchCV to tune model hyperparameters and generate the \"best\" model\n* not including solver = 'cd', because it is not compatible with the other beta_loss functions and we can compare with above results\n* including text transformation options for 'simple', 'wordnet', and 'snowball'\n* not including init = 'nndsvd' as option, because it is not compatible with the other beta_loss functions\n\nFor the GridSearchCV process, we will:\n* Create a custom scorer function to work with the NMF model and categorical response needed to determine the accuracy\n* Perform a GridSearchCV process for the text transformer and TF-IDF vectorizer hyperparameters\n* Perform a GridSearchCV process for the NMF model hyperparameters, using the best text transformer and TF-IDF vectorizer","metadata":{"papermill":{"duration":0.022877,"end_time":"2025-08-03T20:17:13.045115","exception":false,"start_time":"2025-08-03T20:17:13.022238","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a wrapper class to support a customer scoring function for a pipeline/GridSearchCV since NMF doesn't support .predict()\ndef create_nmf_scorer(score_func):\n    class NMFScorer:\n        def __init__(self, score_func):\n            self.score_func = score_func\n\n        def __call__(self, estimator, X, y_true, sample_weight=None):\n            return self.score_func(estimator, X, y_true)\n\n    return NMFScorer(score_func)\n\n# Create a custom scorer for GridSearchCV, using the label_permute_compare function\ndef nmf_category_scorer(estimator, X, y):\n    # Get the transform for the current model\n    doc_topic_matrix = estimator.transform(X)\n\n    # Get dominant topic for each document\n    predicted_topics = doc_topic_matrix.argmax(axis=1)\n\n    # Use your label_permute_compare function\n    labels = np.unique(y).tolist()\n    indices, best_accuracy = label_permute_compare(y, predicted_topics, labels)\n\n    return best_accuracy\n\n# Initialize the custom scorer\ncategory_scorer = create_nmf_scorer(nmf_category_scorer)","metadata":{"ExecuteTime":{"end_time":"2025-08-02T17:05:17.531366Z","start_time":"2025-08-02T17:05:17.526392Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:13.829622Z","iopub.execute_input":"2025-08-04T05:13:13.829939Z","iopub.status.idle":"2025-08-04T05:13:13.838776Z","shell.execute_reply.started":"2025-08-04T05:13:13.829909Z","shell.execute_reply":"2025-08-04T05:13:13.837363Z"},"papermill":{"duration":0.033263,"end_time":"2025-08-03T20:17:13.102080","exception":false,"start_time":"2025-08-03T20:17:13.068817","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tune the Text Transformer and TF-IDF Vectorizer\n\nLet's run a GridSearchCV process on the text transformation and TF-IDF vectorizer to find the \"best\" parameter configuration for our data. We'll just use the NMF model from above for this process.","metadata":{"papermill":{"duration":0.023049,"end_time":"2025-08-03T20:17:13.149544","exception":false,"start_time":"2025-08-03T20:17:13.126495","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Use stratified K-fold to maintain class distribution\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Define parameter grid for TF-IDF options\ntfidf_param_grid = {\n    'text_cleaner__method': ['simple', 'wordnet', 'snowball'],\n    'tfidf__min_df': [3, 5, 10],  # Document frequency threshold\n    'tfidf__max_df': [0.85, 0.9, 0.95],  # Ignore terms that appear too frequently\n    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Unigrams, bigrams, and trigrams\n    'tfidf__norm': ['l1', 'l2'],  # Normalization method\n}\n\n# Utilize caching to avoid processing times for recomputing text transformation on every iteration\nfrom joblib import Memory\ncache_dir = './cachedir'\nos.makedirs(cache_dir, exist_ok=True)\nmemory = Memory(cache_dir, verbose=0)\n\n# Create a pipeline\ntfidf_pipeline = Pipeline([\n    ('text_cleaner', text_cleaner_simple),\n    ('tfidf', tfidf_vectorizer),\n    ('nmf', nmf_model)\n], memory=memory)\n\n# Transform the text using the 'simple' transformer initialized above\nX_train_simple = text_cleaner_simple.transform(X_train)\n\n# Create GridSearchCV with the custom scorer and the current NMF model\nrun_NMF = True\nif run_NMF:  # flag so that this isn't run on every version/submission\n    tfidf_grid_search = GridSearchCV(\n        tfidf_pipeline,\n        param_grid=tfidf_param_grid,\n        scoring=category_scorer,\n        cv=cv,\n        n_jobs=1,\n        verbose=1\n    )\n    \n    # Run grid search with the article text already transformed and vectorized\n    tfidf_grid_search.fit(X_train_simple, y_train)\n    \n    print(\"\\nBest score:\", tfidf_grid_search.best_score_)\n    print(\"Best_params:\", tfidf_grid_search.best_params_)\nelse:\n    print(\"skipping GridSearchCV for text transform and TF-IDF vectorizer, as it has already been run in a previous version.\")\n    \n# Cleanup cache\nmemory.clear()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T20:35:50.530021Z","start_time":"2025-08-02T20:17:55.225229Z"},"execution":{"iopub.status.busy":"2025-08-04T05:13:13.839693Z","iopub.execute_input":"2025-08-04T05:13:13.839941Z","iopub.status.idle":"2025-08-04T05:47:42.436739Z","shell.execute_reply.started":"2025-08-04T05:13:13.839921Z","shell.execute_reply":"2025-08-04T05:47:42.435486Z"},"papermill":{"duration":0.232839,"end_time":"2025-08-03T20:17:13.405871","exception":false,"start_time":"2025-08-03T20:17:13.173032","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tune NMF Hyperparameters\n\nNow that we have the \"best\" configuration for the text transformer and TF-IDF vectorizer, let's setup and run GridSearchCV to find the best NMF model hyperparameters.","metadata":{"papermill":{"duration":0.02298,"end_time":"2025-08-03T20:17:13.452239","exception":false,"start_time":"2025-08-03T20:17:13.429259","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save the best text transformer options\nbest_text_cleaner = TextCleaner(method='wordnet', max_word_count=792, additional_words=remove_common)\n\n# Update the TF-IDF vectorizer with the best options\nbest_tfidf_vectorizer = TfidfVectorizer(\n    min_df=3,\n    max_df=0.85,\n    analyzer='word',\n    ngram_range=(1, 2),\n    norm='l2',\n    sublinear_tf=True,\n    token_pattern=r'\\b\\w+\\b'\n)\n\n# Define parameter grid for the NMF model test options\nnmf_param_grid = {\n    'solver': ['mu'],\n    'beta_loss': ['frobenius', 'kullback-leibler'],\n    'alpha_H': [0.0, 0.1, 0.5],\n    'init': ['random', 'nndsvda', 'nndsvdar']\n}\n\n# Transform and vectorize the text\nX_train_cleaned = best_tfidf_vectorizer.fit_transform(best_text_cleaner.transform(X_train))\n\n# Create GridSearchCV with your custom scorer\nif run_NMF:  # flag so that this isn't run on every version/submission\n    nmf_grid_search = GridSearchCV(\n        nmf_model,\n        param_grid=nmf_param_grid,\n        scoring=category_scorer,\n        cv=cv,\n        n_jobs=-1,\n        verbose=1\n    )\n    \n    # Run grid search with the article text already transformed and vectorized\n    nmf_grid_search.fit(X_train_cleaned, y_train)\n    \n    print(\"\\nBest model:\", nmf_grid_search.best_estimator_)\n    print(\"Best score:\", nmf_grid_search.best_score_)\n    print(\"Best_params:\", nmf_grid_search.best_params_)\nelse:\n    print(\"skipping GridSearchCV for NMF hyperparameter optimization, as it has already been run in a previous version.\")\n    \n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T20:37:51.121076Z","start_time":"2025-08-02T20:36:57.194933Z"},"execution":{"iopub.status.busy":"2025-08-04T05:47:42.443643Z","iopub.execute_input":"2025-08-04T05:47:42.444053Z","iopub.status.idle":"2025-08-04T05:49:57.981649Z","shell.execute_reply.started":"2025-08-04T05:47:42.444019Z","shell.execute_reply":"2025-08-04T05:49:57.980185Z"},"papermill":{"duration":16.684087,"end_time":"2025-08-03T20:17:30.159617","exception":false,"start_time":"2025-08-03T20:17:13.475530","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train the \"Best\" NMF Model\n\nNow we can save the \"best\" NMF model and run it against the test subset of the Train data.","metadata":{"papermill":{"duration":0.023628,"end_time":"2025-08-03T20:17:30.208910","exception":false,"start_time":"2025-08-03T20:17:30.185282","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save the best estimator\nbest_nmf_model = NMF(\n    n_components=5,\n    random_state=42,\n    max_iter=300,\n    solver='mu',\n    beta_loss='frobenius',\n    alpha_H=0.0,\n    l1_ratio=0.5,\n    init='nndsvda'\n)\n\n# Create a pipeline with the best model\nbest_nmf_pipeline = (Pipeline([\n    ('text_cleaner', best_text_cleaner),\n    ('tfidf', best_tfidf_vectorizer),\n    ('nmf', best_nmf_model)\n]))\n\n# Perform a fit_transform on the training data\ny_hat_train = best_nmf_pipeline.fit_transform(X_train, y_train)\ny_pred_train = y_hat_train.argmax(axis=1)\n\n# Re-generate the category mapping, to make sure nothing has changed\ntopic_to_category_idx, accuracy = label_permute_compare(y_train, y_pred_train, base_category_list)\ncategory_mapping = {i: base_category_list[idx] for i, idx in enumerate(topic_to_category_idx)}\n\n# Run the best pipeline/model on the test subset of the Train data\ny_hat = best_nmf_pipeline.transform(X_test)\ny_pred = y_hat.argmax(axis=1)\ny_pred_categories = [category_mapping[topic] for topic in y_pred]\n\n# Calculate accuracy\ntest_accuracy = accuracy_score(y_test, y_pred_categories)\nprint(f\"Best Model Accuracy on the test subset: {test_accuracy:.4f}\")\n\n# Create confusion matrix\ncm = confusion_matrix(y_test, y_pred_categories)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=base_category_list, yticklabels=base_category_list)\nplt.title('Confusion Matrix')\nplt.ylabel('True Category')\nplt.xlabel('Predicted Category')\nplt.tight_layout()\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2025-08-02T21:25:07.948429Z","start_time":"2025-08-02T21:24:56.557189Z"},"execution":{"iopub.status.busy":"2025-08-04T05:49:57.982855Z","iopub.execute_input":"2025-08-04T05:49:57.983137Z","iopub.status.idle":"2025-08-04T05:50:17.675181Z","shell.execute_reply.started":"2025-08-04T05:49:57.983111Z","shell.execute_reply":"2025-08-04T05:50:17.674161Z"},"papermill":{"duration":17.053638,"end_time":"2025-08-03T20:17:47.287538","exception":false,"start_time":"2025-08-03T20:17:30.233900","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Predict on Competition Test Data Set with NMF\n\nFinally, generate a prediction on the competition Test data set using the best NMF model.","metadata":{"papermill":{"duration":0.023716,"end_time":"2025-08-03T20:17:47.335682","exception":false,"start_time":"2025-08-03T20:17:47.311966","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Generate predictions for submission Test data set\nnmf_test = bbcnews_test.copy()\n\n# Predict the target category on the Test data set using the best nmf pipeline\ny_hat_test = best_nmf_pipeline.transform(nmf_test['Text'])\ny_pred = y_hat_test.argmax(axis=1)\ny_pred_categories = [category_mapping[topic] for topic in y_pred]\nnmf_test['Category'] = y_pred_categories\n\n# drop unneeded columns\nnmf_test = nmf_test.drop(['Text'], axis=1)\nnmf_test.head(10)\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T20:39:49.056118Z","start_time":"2025-08-02T20:39:43.138526Z"},"execution":{"iopub.status.busy":"2025-08-04T05:50:17.676261Z","iopub.execute_input":"2025-08-04T05:50:17.676656Z","iopub.status.idle":"2025-08-04T05:50:26.450800Z","shell.execute_reply.started":"2025-08-04T05:50:17.676623Z","shell.execute_reply":"2025-08-04T05:50:26.449830Z"},"papermill":{"duration":8.448361,"end_time":"2025-08-03T20:17:55.808852","exception":false,"start_time":"2025-08-03T20:17:47.360491","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"... and create the prediction submission file.","metadata":{"papermill":{"duration":0.025215,"end_time":"2025-08-03T20:17:55.860328","exception":false,"start_time":"2025-08-03T20:17:55.835113","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%script echo \"skipping - not saving NMF results for this version\"\n# save submission for NMF model\ntry:\n    nmf_test.to_csv('submission.csv', index=False)\n    print(\"Submission file saved.\")\nexcept PermissionError:\n    print(\"Could not write the submission file.\")\n","metadata":{"ExecuteTime":{"end_time":"2025-08-01T21:59:40.740375Z","start_time":"2025-08-01T21:59:40.722247Z"},"execution":{"iopub.status.busy":"2025-08-04T05:50:26.451847Z","iopub.execute_input":"2025-08-04T05:50:26.452091Z","iopub.status.idle":"2025-08-04T05:50:26.464657Z","shell.execute_reply.started":"2025-08-04T05:50:26.452073Z","shell.execute_reply":"2025-08-04T05:50:26.463602Z"},"papermill":{"duration":0.049555,"end_time":"2025-08-03T20:17:55.934987","exception":false,"start_time":"2025-08-03T20:17:55.885432","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3. Compare with Supervised Learning\n\nFor this section, we will determine a \"best\" supervised learning model and then compare the results with the NFM unsupervised learning model. The supervised learning models that we will evaluate are:\n* Support Vector Machine (SVM), using LinearSVC\n* Logistic Regression\n* Random Forest Classifier\n\nWe will use GridSearchCV to determine which model and hyperparameters perform the \"best\" for the comparison","metadata":{"papermill":{"duration":0.023916,"end_time":"2025-08-03T20:17:55.983791","exception":false,"start_time":"2025-08-03T20:17:55.959875","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Base pipeline for testing the three models\nclassifier_pipeline = Pipeline([('classifier', LogisticRegression())])\n\n# Support Vector Maching (SVM) model - LinearSVC\nsvm = LinearSVC(\n    C=1.0,\n    dual=False,\n    loss='squared_hinge',\n    class_weight=None,\n    max_iter=10000            # increased due to failure to converge warnings\n)\n\n# Logistic Regression model\nlr = LogisticRegression(\n    C=1.0,\n    penalty='l2',\n    solver='liblinear',\n    max_iter=10000,           # increased due to failure to converge warnings\n    class_weight='balanced',\n    random_state=42,\n    multi_class='ovr'\n)\n\n# Random Forests Classifier model\nrfc = RandomForestClassifier(\n    n_estimators=300,\n    max_depth=30,\n    min_samples_split=5,\n    min_samples_leaf=1,\n    bootstrap=True,\n    class_weight='balanced',\n    random_state=42,\n    n_jobs=-1\n)\n\nclassifier_param_grid = [\n    {\n        'classifier': [lr],\n        'classifier__C': [0.1, 1.0, 10],\n        'classifier__penalty': ['l1', 'l2'],\n    },\n    {\n        'classifier': [rfc],\n        'classifier__n_estimators': [200, 300],\n        'classifier__max_depth': [None, 30, 50],\n        'classifier__min_samples_split': [2, 5],\n        'classifier__min_samples_leaf': [1, 2],\n        'classifier__class_weight': ['balanced', None],\n    },\n    {\n        'classifier': [svm],\n        'classifier__C': [0.1, 1.0, 10],\n        'classifier__penalty': ['l1', 'l2'],\n        'classifier__class_weight': ['balanced', None],\n    }\n]\n\n# Create GridSearchCV\nrun_Supervised = True  # ran GridSearchCV for Supervised model comparison in earlier Version\nif run_Supervised:\n    grid_search = GridSearchCV(\n        classifier_pipeline,\n        classifier_param_grid,\n        cv=cv,\n        scoring='accuracy',\n        n_jobs=-1,\n        verbose=1\n    )\n    \n    # Run grid search with the article text already transformed and vectorized\n    grid_search.fit(X_train_cleaned, y_train)\n    \n    print(\"\\nBest model:\", grid_search.best_estimator_)\n    print(\"Best score:\", grid_search.best_score_)\n    print(\"Best_params:\", grid_search.best_params_)\nelse:\n    print(\"skipping GridSearchCV for supervised learning model selection, as it has already been run in a previous version.\")\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T20:58:08.624766Z","start_time":"2025-08-02T20:57:20.453163Z"},"execution":{"iopub.status.busy":"2025-08-04T06:09:34.167746Z","iopub.execute_input":"2025-08-04T06:09:34.168102Z","iopub.status.idle":"2025-08-04T06:13:12.867162Z","shell.execute_reply.started":"2025-08-04T06:09:34.168077Z","shell.execute_reply":"2025-08-04T06:13:12.866197Z"},"papermill":{"duration":0.03724,"end_time":"2025-08-03T20:17:56.045271","exception":false,"start_time":"2025-08-03T20:17:56.008031","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train/Test the Suppor Vector Machine (SVM) Model - LinearSVC\n\nLinearSVC had the higher accuracy score of the three, so we save that model as the \"best\" supervised learning model and predict against the test subset data.","metadata":{"papermill":{"duration":0.026203,"end_time":"2025-08-03T20:17:56.096715","exception":false,"start_time":"2025-08-03T20:17:56.070512","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Test the best SVM model on the test subset of the Train data\nbest_svm_model = LinearSVC(\n    C=1.0,\n    dual=False,\n    loss='squared_hinge',\n    class_weight='balanced',\n    penalty='l2',\n    max_iter=10000\n)\n\nbest_svm_pipeline = Pipeline([\n    ('text_cleaner', best_text_cleaner),\n    ('tfidf', best_tfidf_vectorizer),\n    ('svm', best_svm_model)\n])\n\n# Train the model\nbest_svm_pipeline.fit(X_train, y_train)\n\n# Predict on test data\ny_pred_svm = best_svm_pipeline.predict(X_test)\n\n# Calculate accuracy\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nprint(f\"Accuracy on test set: {accuracy_svm:.4f}\")\n\n# Detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_svm))","metadata":{"ExecuteTime":{"end_time":"2025-08-02T21:01:16.825488Z","start_time":"2025-08-02T21:01:04.913618Z"},"execution":{"iopub.status.busy":"2025-08-04T05:53:54.870705Z","iopub.execute_input":"2025-08-04T05:53:54.870967Z","iopub.status.idle":"2025-08-04T05:54:12.219414Z","shell.execute_reply.started":"2025-08-04T05:53:54.870945Z","shell.execute_reply":"2025-08-04T05:54:12.218340Z"},"papermill":{"duration":16.500446,"end_time":"2025-08-03T20:18:12.622301","exception":false,"start_time":"2025-08-03T20:17:56.121855","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Predict on Competition Test Data Set with SVM\n\nNext, we can use this model to generate a prediction on the competition Test data set.","metadata":{"papermill":{"duration":0.024326,"end_time":"2025-08-03T20:18:12.671318","exception":false,"start_time":"2025-08-03T20:18:12.646992","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Generate predictions for submission Test data set\nsvm_test = bbcnews_test.copy()\n\n# Predict the target category on the Test data set using the best nmf pipeline\nsvm_test['Category'] = best_svm_pipeline.predict(svm_test['Text'])\n\n# drop unneeded columns\nsvm_test = svm_test.drop(['Text'], axis=1)\nsvm_test.head(10)\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T21:02:00.420196Z","start_time":"2025-08-02T21:01:53.661479Z"},"execution":{"iopub.status.busy":"2025-08-04T05:54:12.220587Z","iopub.execute_input":"2025-08-04T05:54:12.220897Z","iopub.status.idle":"2025-08-04T05:54:21.082215Z","shell.execute_reply.started":"2025-08-04T05:54:12.220864Z","shell.execute_reply":"2025-08-04T05:54:21.081338Z"},"papermill":{"duration":8.453601,"end_time":"2025-08-03T20:18:21.149401","exception":false,"start_time":"2025-08-03T20:18:12.695800","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"... and then save a corresponding submission file.","metadata":{"papermill":{"duration":0.024759,"end_time":"2025-08-03T20:18:21.200946","exception":false,"start_time":"2025-08-03T20:18:21.176187","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%script echo \"skipping - not saving SVM results for this version\"\n# save submission for SVM model\ntry:\n    svm_test.to_csv('submission.csv', index=False)\nexcept PermissionError:\n    print(\"Could not write the submission file.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-04T05:54:21.083250Z","iopub.execute_input":"2025-08-04T05:54:21.083870Z","iopub.status.idle":"2025-08-04T05:54:21.093544Z","shell.execute_reply.started":"2025-08-04T05:54:21.083837Z","shell.execute_reply":"2025-08-04T05:54:21.092222Z"},"papermill":{"duration":0.036892,"end_time":"2025-08-03T20:18:21.262740","exception":false,"start_time":"2025-08-03T20:18:21.225848","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### NMF vs. SVM\n\nOverall, it looks like the LinearSVC supervised learning model performed better on the category prediction over the Non-negative Matrix Factorization unsupervised model. In general, this makes sense, given that the supervised model can learn based on a known outcome, while the unsupervised model is clustering based on a determination of similarities/differences.","metadata":{"papermill":{"duration":0.024999,"end_time":"2025-08-03T20:18:21.314968","exception":false,"start_time":"2025-08-03T20:18:21.289969","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Does training sample size matter?\n\nFor experimentation, we are going to compare the NMF and LinearSVC models across different training sample sizes. This will be done by creating splits for 20%, 40%, 60%, and 80%, running fit/predict for each model, and then comparing the results across each.","metadata":{"papermill":{"duration":0.028082,"end_time":"2025-08-03T20:18:21.368259","exception":false,"start_time":"2025-08-03T20:18:21.340177","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Split the Train data set into different size train and test sets to evaluate supervised model(s)\nsplits = [0.2, 0.4, 0.6, 0.8]\n\n# DataFrame to store results\nsplit_results = pd.DataFrame(\n    {\n        'nmf': [0.0] * len(splits),\n        'svm': [0.0] * len(splits)\n    },\n    index=splits\n)\nsplit_results.index.name = 'split'\n\n# Iterate the test for each training set size\nfor split in splits:\n    X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n        bbcnews_train.Text,\n        bbcnews_train.Category,\n        test_size=split,\n        random_state=42,\n        # stratify=bbcnews_train.Category  # Maintain class distribution\n    )\n\n    # fit/predict for NMF\n    y_hat_train_s = best_nmf_pipeline.fit_transform(X_train_s, y_train_s)\n    y_pred_train_s = y_hat_train_s.argmax(axis=1)\n    labels_s = np.unique(y_train_s).tolist()\n    nmf_train_idx, nmf_train_accuracy = label_permute_compare(y_train_s, y_pred_train_s, labels_s)\n    category_mapping_s = {i: labels_s[idx] for i, idx in enumerate(nmf_train_idx)}\n\n    # Run on the test subset data for NMF\n    y_hat_s = best_nmf_pipeline.transform(X_test_s)\n    y_pred_s = y_hat_s.argmax(axis=1)\n    y_pred_categories = [category_mapping_s[topic] for topic in y_pred_s]\n    nmf_test_accuracy = accuracy_score(y_test_s, y_pred_categories)\n\n    # Save results\n    split_results.at[split, 'nmf'] = accuracy_score(y_test_s, y_pred_categories)\n\n    # fit/predit for SVM\n    best_svm_pipeline.fit(X_train_s, y_train_s)\n\n    # Run on the test subset data for SVM\n    y_pred_s = best_svm_pipeline.predict(X_test_s)\n    split_results.at[split, 'svm'] = accuracy_score(y_test_s, y_pred_s)\n\nsplit_results","metadata":{"ExecuteTime":{"end_time":"2025-08-02T22:47:17.993108Z","start_time":"2025-08-02T22:45:46.671476Z"},"execution":{"iopub.status.busy":"2025-08-04T05:54:21.094720Z","iopub.execute_input":"2025-08-04T05:54:21.095008Z","iopub.status.idle":"2025-08-04T05:56:36.474748Z","shell.execute_reply.started":"2025-08-04T05:54:21.094986Z","shell.execute_reply":"2025-08-04T05:56:36.473677Z"},"papermill":{"duration":129.458416,"end_time":"2025-08-03T20:20:30.853186","exception":false,"start_time":"2025-08-03T20:18:21.394770","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Again, the LinearSVC supervised learning model had better accuracy than NMF across all variations of the split percentage.","metadata":{"papermill":{"duration":0.024263,"end_time":"2025-08-03T20:20:30.902268","exception":false,"start_time":"2025-08-03T20:20:30.878005","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Ensemble Approach\n\nFor the final evaluation, let's see how an ensemble would work with both the NMF and LinearSVC models together. As an experiment, I will also add a Random Forest Classifier and test the voting weights to see the affects on the outcome. Instead of creating a custom transformer to enable NMF predictions, the NMF results were fed into a LogisticRegression classifier for the category prediction.","metadata":{"papermill":{"duration":0.024349,"end_time":"2025-08-03T20:20:30.951129","exception":false,"start_time":"2025-08-03T20:20:30.926780","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Build an Ensemble that uses the NMF/Logistic Regression, SVM, and RFC models together\n\n# Create a NMF-based classifier with LogisticRegression to generate predictions in a supervised learning process\nnmf_classifier_pipeline = Pipeline([\n    ('text_cleaner', clone(best_text_cleaner)),\n    ('tfidf', clone(best_tfidf_vectorizer)),\n    ('nmf_extractor', best_nmf_model),\n    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n])\n\n# Create a calibrated SVM classifier to return results in probability estimates\ncalibrated_svm_pipeline = Pipeline([\n    ('text_cleaner', clone(best_text_cleaner)),\n    ('tfidf', clone(best_tfidf_vectorizer)),\n    ('svm', CalibratedClassifierCV(best_svm_model, cv=5))\n])\n\n# Create a calibrated Random Forest Classifier\ncalibrated_rfc_pipeline = Pipeline([\n    ('text_cleaner', clone(best_text_cleaner)),\n    ('tfidf', clone(best_tfidf_vectorizer)),\n    ('rfc', CalibratedClassifierCV(rfc, cv=5))\n])\n\n# Create voting ensemble\nensemble = VotingClassifier(\n    estimators=[\n        ('nmf', nmf_classifier_pipeline),\n        ('svm', calibrated_svm_pipeline),\n        ('rfc', calibrated_rfc_pipeline)\n    ],\n    voting='soft',\n    weights=[0.2, 0.4, 0.4]\n)\n\n# Fit the ensemble\nensemble.fit(X_train, y_train)\n\n# Evaluate the model on test data\ny_pred_ensemble = ensemble.predict(X_test)\n\n# Calculate accuracy\naccuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\nprint(f\"Accuracy on test set: {accuracy_ensemble:.4f}\")\n\n# Detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_ensemble))","metadata":{"ExecuteTime":{"end_time":"2025-08-02T19:50:06.597672Z","start_time":"2025-08-02T19:49:29.033869Z"},"execution":{"iopub.status.busy":"2025-08-04T05:56:36.475967Z","iopub.execute_input":"2025-08-04T05:56:36.476300Z","iopub.status.idle":"2025-08-04T05:57:36.544962Z","shell.execute_reply.started":"2025-08-04T05:56:36.476250Z","shell.execute_reply":"2025-08-04T05:57:36.543939Z"},"papermill":{"duration":57.618826,"end_time":"2025-08-03T20:21:28.594699","exception":false,"start_time":"2025-08-03T20:20:30.975873","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Note on Voting Weights\n\nPlaying with the weight parameters, I found that the LinearSVC model still had the best accuracy and contributed the most to higher accuracy outcomes. The Random Forest Classifier also had a reasonable accuracy, with the NMF model seeming to contribute less towards the better prediction accuracies. In the end, the best prediction accuracy on the test subset data seemed to fall around 20%, 40%, 40% for NMF/LR, SVM, and RFC, respectively.","metadata":{"papermill":{"duration":0.024652,"end_time":"2025-08-03T20:21:54.380230","exception":false,"start_time":"2025-08-03T20:21:54.355578","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Predict on Cempetition Test Data Set with Ensemble Method","metadata":{}},{"cell_type":"code","source":"# Generate predictions for submission Test data set\nensemble_test = bbcnews_test.copy()\n\n# Predict the target category on the Test data set using the best nmf pipeline\nensemble_test['Category'] = ensemble.predict(ensemble_test['Text'])\n\n# drop unneeded columns\nensemble_test = ensemble_test.drop(['Text'], axis=1)\nensemble_test.head(10)\n","metadata":{"ExecuteTime":{"end_time":"2025-08-02T19:52:44.321797Z","start_time":"2025-08-02T19:52:25.817360Z"},"execution":{"iopub.status.busy":"2025-08-04T05:57:36.545963Z","iopub.execute_input":"2025-08-04T05:57:36.546223Z","iopub.status.idle":"2025-08-04T05:58:03.861214Z","shell.execute_reply.started":"2025-08-04T05:57:36.546194Z","shell.execute_reply":"2025-08-04T05:58:03.860247Z"},"papermill":{"duration":25.64505,"end_time":"2025-08-03T20:21:54.265061","exception":false,"start_time":"2025-08-03T20:21:28.620011","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save submission for SVM model\ntry:\n    svm_test.to_csv('submission.csv', index=False)\nexcept PermissionError:\n    print(\"Could not write the submission file.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-04T05:58:03.862368Z","iopub.execute_input":"2025-08-04T05:58:03.862640Z","iopub.status.idle":"2025-08-04T05:58:03.876664Z","shell.execute_reply.started":"2025-08-04T05:58:03.862619Z","shell.execute_reply":"2025-08-04T05:58:03.875675Z"},"papermill":{"duration":0.038806,"end_time":"2025-08-03T20:21:54.330344","exception":false,"start_time":"2025-08-03T20:21:54.291538","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusions\n\nThe project goals were to determine how well a Non-negative Matrix Factorization model would work on categorizing the BBC News Articles data in an unsupervised learning approach. We then wanted to run a supervised learning model against the same data set and examine how the results compared to the unsupervised model. For this step, we evaluated several supervised learning models and selected a SVM model (LinearSVC) as it had the highest accuracy scores. For additional experiments, we also ran tests to compare how the NMF and SVM models performed across various splits for the training data, to determine if that could be a factor for selecting the supervised versus unsupervised learning model approach. Finally, we generated an ensemble method, combining several models,to determine if that would benefit us for this data set.\n\nOur final results...\n\nFor our final results, we used the WordNet text transformer and TF-IDF vectorizer, split the Train data into training and testing data sets, and used the same data sets to train/test all models/approaches. The project progressed from the unsupervised NMF model, to the supervised SVM (LinearSVC) model, and then to the supervised ensemble model, submitting competition results on the BBC News Train data set for each approach. The following were the Private/Public Score results:\n\n* NMF:        0.94965 (Version 1 notebook)\n* LinearSVC:  0.98503 (Version 3 notebook)\n* Ensemble:   0.98503 (Version 6 notebook)\n\nBased on the Test submission results, the LinearSVC SVM model performed consistently better throughout the process. The Ensemble method scored similarly, as it was likely influenced by the results generated from the LinearSVC component (40% voting weight).","metadata":{"execution":{"iopub.status.busy":"2025-08-04T05:58:03.877769Z","iopub.execute_input":"2025-08-04T05:58:03.878058Z","iopub.status.idle":"2025-08-04T05:58:03.893984Z","shell.execute_reply.started":"2025-08-04T05:58:03.878035Z","shell.execute_reply":"2025-08-04T05:58:03.892971Z"},"papermill":{"duration":0.031972,"end_time":"2025-08-03T20:21:54.437089","exception":false,"start_time":"2025-08-03T20:21:54.405117","status":"completed"},"tags":[]}}]}